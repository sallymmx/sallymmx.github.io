(window.webpackJsonp=window.webpackJsonp||[]).push([[24],{280:function(e,n,t){},300:function(e,n,t){"use strict";t(280)},318:function(e,n,t){"use strict";t.r(n);t(300);var r=t(14),o=Object(r.a)({},(function(){var e=this,n=e._self._c;return n("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[n("ProfileSection",{attrs:{frontmatter:e.$page.frontmatter}}),e._v(" "),n("h2",{attrs:{id:"about-me"}},[e._v("About Me")]),e._v(" "),n("p",[e._v("I have attended the College of Computer Science & Technology,  Zhejiang University of Technology as an Associate Professor in 2024. My research area includes Robotic Embodied Intelligence, Compute Vision and Multi-media Technology, specifically including video action recognition, object tracking, object detection, depth estimation, text-to-image editing and so on. üí´")]),e._v(" "),n("p",[e._v("My works have been published on top computer vision transactions/conferences (TPAMI, TIP, TMM, CVPR, ICCV, ICLR, AAAI etc) and top robotic conferences (ICRA, IROS).")]),e._v(" "),n("h2",{attrs:{id:"news"}},[e._v("News")]),e._v(" "),n("ul",[n("li",[e._v("[2024] 3 paper is accepted by "),n("strong",[e._v("Neurips 2024 (One oral)")]),e._v("  üéâüéâ")]),e._v(" "),n("li",[e._v("[2024] I will serve as a PC of IEEE BIBM 2024.")]),e._v(" "),n("li",[e._v("[2024] 1 paper is accepted by "),n("strong",[e._v("ACM MM 2024")]),e._v(" üéâ")]),e._v(" "),n("li",[e._v("[2024] 1 paper is accepted by "),n("strong",[e._v("ICLR 2024")]),e._v("  üéâ")]),e._v(" "),n("li",[e._v("[2024] 2 papers are accepted by "),n("strong",[e._v("AAAI 2024 (One "),n("font",{attrs:{color:"red"}},[e._v("Oral")]),e._v(")")],1),e._v("  üéâüéâüéâ")]),e._v(" "),n("li",[e._v("[Dec, 2023] 1 paper is accepted by "),n("strong",[e._v("TPAMI 2023")]),e._v("  üéâüéâ")]),e._v(" "),n("li",[e._v("[July, 2023] 2 papers are accepted by "),n("strong",[e._v("ICCV 2023")]),e._v("  üéâ")]),e._v(" "),n("li",[e._v("[Nov, 2023] 1 paper is accepted by "),n("strong",[e._v("TNNLS 2023")]),e._v("  üéâ")]),e._v(" "),n("li",[e._v("[Jan, 2023] 1 paper is accepted by "),n("strong",[e._v("AAAI 2023")]),e._v("  üéâ")]),e._v(" "),n("li",[e._v("[Sep, 2022] 1 paper is accepted by "),n("strong",[e._v("TIP 2022")]),e._v("  üéâ")]),e._v(" "),n("li",[e._v("[Jul, 2022]   **First Prize of Science and Technology Progress of Zhejiang Province (ÊµôÊ±üÁúÅÁßëÊäÄËøõÊ≠•‰∏ÄÁ≠âÂ•ñ) **üéâ")]),e._v(" "),n("li",[e._v("[Jul, 2022] 1 paper is accepted by "),n("strong",[e._v("ECCV 2022")]),e._v("  üéâ")]),e._v(" "),n("li",[e._v("[Apr, 2022] 1 paper is accepted by "),n("strong",[e._v("TPAMI 2022")]),e._v("  üéâüéâüéâ")]),e._v(" "),n("li",[e._v("[Nov, 2021] 1 papers is accepted by "),n("strong",[e._v("TNNLS 2021")]),e._v("  üéâ")]),e._v(" "),n("li",[e._v("[Aug, 2021] 2 papers are accepted by "),n("strong",[e._v("ICCV 2021")]),e._v("  üéâüéâ")]),e._v(" "),n("li",[e._v("[May, 2021] 1 paper is accepted by "),n("strong",[e._v("TMM 2021")]),e._v("  üéâüéâ")]),e._v(" "),n("li",[e._v("[Feb, 2021] "),n("a",{attrs:{href:"https://www.cie-info.org.cn/site/content/4047.html",target:"_blank",rel:"noopener noreferrer"}},[n("strong",[e._v("Excellent master dissertation")]),n("OutboundLink")],1),e._v("  of "),n("em",[e._v("Chinese Institute of Electronics (‰∏≠ÂõΩÁîµÂ≠êÂ≠¶‰ºö)")])]),e._v(" "),n("li",[e._v("[Dec, 2020] 4 papers are accepted by "),n("strong",[e._v("AAAI 2021")]),e._v("  üéâüéâ")]),e._v(" "),n("li",[e._v("[Mar, 2020] 1 paper is accepted by "),n("strong",[e._v("CVPR 2020")]),e._v(" üéâ")]),e._v(" "),n("li",[e._v("[Nov, 2019] 2 papers are accepted by "),n("strong",[e._v("AAAI 2020")]),e._v(" üéâ")])]),e._v(" "),n("h2",{attrs:{id:"education-experiences"}},[e._v("Education & Experiences")]),e._v(" "),n("ul",[n("li",[n("strong",[e._v("Zhejiang University of Technology")]),e._v(" Associate Professor,from 2024")]),e._v(" "),n("li",[n("strong",[e._v("Zhejiang University")]),e._v(" Bachelor, Master, PhD")]),e._v(" "),n("li",[n("strong",[e._v("SenseTime Smart City Group")]),e._v("  [2018-2020]  Researcher")])]),e._v(" "),n("h2",{attrs:{id:"publications"}},[e._v("Publications")]),e._v(" "),n("p",[n("RouterLink",{attrs:{to:"/publications/"}},[e._v("‚Üí Full list")])],1),e._v(" "),n("ProjectCard",{attrs:{image:"/projects/aaai2024.png",hideBorder:"true"}},[n("p",[n("strong",[e._v("A Multimodal, Multi-Task Adapting Framework for Video Action Recognition")])]),e._v(" "),n("p",[n("strong",[e._v("Mengmeng Wang")]),e._v(", Jiazheng Xing, Boyuan Jiang,  Jun Chen, Jianbiao Mei, Xingxing Zuo, Guang Dai, Jingdong Wang, Yong Liu*")]),e._v(" "),n("p",[e._v("Proceedings of the AAAI Conference on Artificial Intelligence ("),n("strong",[e._v("AAAI")]),e._v("), 2024, ("),n("font",{attrs:{color:"red"}},[n("strong",[e._v("Oral")])]),e._v(")")],1),e._v(" "),n("p",[e._v("["),n("a",{attrs:{href:"https://ojs.aaai.org/index.php/AAAI/article/view/28361",target:"_blank",rel:"noopener noreferrer"}},[e._v("PDF"),n("OutboundLink")],1),e._v("]")])]),e._v(" "),n("ProjectCard",{attrs:{image:"/projects/actionclip.png",hideBorder:"true"}},[n("p",[n("strong",[e._v("ActionCLIP: Adapting Language-Image Pretrained Models for Video Action Recognition")])]),e._v(" "),n("p",[n("strong",[e._v("Mengmeng Wang")]),e._v(", Jiazheng Xing, Jianbiao Mei, Yong Liu, Yunliang Jiang")]),e._v(" "),n("p",[e._v("IEEE Transactions on Neural Networks and Learning Systems ("),n("strong",[e._v("TNNLS")]),e._v("), 2023")]),e._v(" "),n("p",[e._v("["),n("a",{attrs:{href:"https://github.com/sallymmx/ActionCLIP",target:"_blank",rel:"noopener noreferrer"}},[e._v("Code"),n("OutboundLink")],1),e._v("] ["),n("a",{attrs:{href:"https://arxiv.org/abs/2109.08472",target:"_blank",rel:"noopener noreferrer"}},[e._v("PDF"),n("OutboundLink")],1),e._v("]")])]),e._v(" "),n("ProjectCard",{attrs:{image:"/projects/corpnet.png",hideBorder:"true"}},[n("p",[n("strong",[e._v("Correlation pyramid network for 3d single object tracking")])]),e._v(" "),n("p",[n("strong",[e._v("Mengmeng Wang")]),e._v(", Teli Ma, Xingxing Zuo, Jiajun Lv, Yong Liu")]),e._v(" "),n("p",[e._v("Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition ("),n("strong",[e._v("CVPR")]),e._v("), 2023")]),e._v(" "),n("p",[e._v("["),n("a",{attrs:{href:"https://openaccess.thecvf.com/content/CVPR2023W/E2EAD/html/Wang_Correlation_Pyramid_Network_for_3D_Single_Object_Tracking_CVPRW_2023_paper.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("PDF"),n("OutboundLink")],1),e._v("]")])]),e._v(" "),n("ProjectCard",{attrs:{image:"/projects/pami2022.png",hideBorder:"true"}},[n("p",[n("strong",[e._v("Learning SpatioTemporal and Motion Features in a Unified 2D Network for Action Recognition")])]),e._v(" "),n("p",[n("strong",[e._v("Mengmeng Wang")]),e._v(", Jiazheng Xing, Jing Su,  Jun Chen, Yong Liu*")]),e._v(" "),n("p",[e._v("IEEE Transactions on Pattern Analysis and Machine Intelligence ("),n("strong",[e._v("TPAMI")]),e._v("), 2022")]),e._v(" "),n("p",[e._v("["),n("a",{attrs:{href:"https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=VSRnUiUAAAAJ&sortby=pubdate&citation_for_view=VSRnUiUAAAAJ:maZDTaKrznsC",target:"_blank",rel:"noopener noreferrer"}},[e._v("PDF"),n("OutboundLink")],1),e._v("]")])]),e._v(" "),n("ProjectCard",{attrs:{image:"/projects/iccv2023.png",hideBorder:"true"}},[n("p",[n("strong",[e._v("Synchronize Feature Extracting and Matching: A Single Branch Framework for 3D Object Tracking")])]),e._v(" "),n("p",[e._v("Teli Ma, "),n("strong",[e._v("Mengmeng Wang")]),e._v(", Jimin Xiao, Huifeng Wu, Yong Liu")]),e._v(" "),n("p",[e._v("Proceedings of the IEEE/CVF International Conference on Computer Vision ("),n("strong",[e._v("ICCV")]),e._v("), 2023")]),e._v(" "),n("p",[e._v("["),n("a",{attrs:{href:"http://openaccess.thecvf.com/content/ICCV2023/html/Ma_Synchronize_Feature_Extracting_and_Matching_A_Single_Branch_Framework_for_ICCV_2023_paper.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("PDF"),n("OutboundLink")],1),e._v("]")])]),e._v(" "),n("ProjectCard",{attrs:{image:"/projects/few1.png",hideBorder:"true"}},[n("p",[n("strong",[e._v("Boosting Few-shot Action Recognition with Graph-guided Hybrid Matching")])]),e._v(" "),n("p",[e._v("Jiazheng Xing, "),n("strong",[e._v("Mengmeng Wang")]),e._v(", Yudi Ruan, Bofan Chen, Yaowei Guo, Boyu Mu, Guang Dai, Jingdong Wang, Yong Liu")]),e._v(" "),n("p",[e._v("Proceedings of the IEEE/CVF International Conference on Computer Vision ("),n("strong",[e._v("ICCV")]),e._v("), 2023")]),e._v(" "),n("p",[e._v("["),n("a",{attrs:{href:"http://openaccess.thecvf.com/content/ICCV2023/html/Xing_Boosting_Few-shot_Action_Recognition_with_Graph-guided_Hybrid_Matching_ICCV_2023_paper.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("PDF"),n("OutboundLink")],1),e._v("]")])]),e._v(" "),n("ProjectCard",{attrs:{image:"/projects/HRNet.gif",hideBorder:"true"}},[n("p",[n("strong",[e._v("HR-Depth : High Resolution Self-Supervised Monocular Depth Estimation")])]),e._v(" "),n("p",[e._v("Xiaoyang Lyu, Liang Liu, "),n("strong",[e._v("Mengmeng Wang")]),e._v(", Xin Kong, Lina Liu, Yong Liu*, Xinxin Chen, Yi Yuan")]),e._v(" "),n("p",[e._v("The Association for the Advance of Artificial Intelligence ("),n("strong",[e._v("AAAI")]),e._v("), 2021")]),e._v(" "),n("p",[e._v("["),n("a",{attrs:{href:"https://github.com/shawLyu/HR-Depth",target:"_blank",rel:"noopener noreferrer"}},[e._v("Code"),n("OutboundLink")],1),e._v("] ["),n("a",{attrs:{href:"https://arxiv.org/pdf/2012.07356.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("PDF"),n("OutboundLink")],1),e._v("]")])]),e._v(" "),n("ProjectCard",{attrs:{image:"/projects/AAAI2020Head.png",hideBorder:"true"}},[n("p",[n("strong",[e._v("FDN: Feature Decoupling Network for Head Pose Estimation")])]),e._v(" "),n("p",[e._v("Hao Zhang, "),n("strong",[e._v("Mengmeng Wang")]),e._v(", Yong Liu Yi Yuan")]),e._v(" "),n("p",[e._v("The Association for the Advance of Artificial Intelligence ("),n("strong",[e._v("AAAI")]),e._v("), 2020")]),e._v(" "),n("p",[e._v("["),n("a",{attrs:{href:"https://ojs.aaai.org/index.php/AAAI/article/view/6974/6828",target:"_blank",rel:"noopener noreferrer"}},[e._v("PDF"),n("OutboundLink")],1),e._v("]")])]),e._v(" "),n("ProjectCard",{attrs:{image:"/projects/stm.png",hideBorder:"true"}},[n("p",[n("strong",[e._v("STM: SpatioTemporal and motion encoding for action recognition")])]),e._v(" "),n("p",[e._v("Boyuan Jiang,  "),n("strong",[e._v("Mengmeng Wang")]),e._v(" *, Weihao Gan, Wei Wu, Junjie Yan.")]),e._v(" "),n("p",[e._v("Proceedings of the IEEE International Conference on Computer Vision ("),n("strong",[e._v("ICCV")]),e._v("). 2019")]),e._v(" "),n("p",[e._v("["),n("a",{attrs:{href:"https://openaccess.thecvf.com/content_ICCV_2019/papers/Jiang_STM_SpatioTemporal_and_Motion_Encoding_for_Action_Recognition_ICCV_2019_paper.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("PDF"),n("OutboundLink")],1),e._v("]")])]),e._v(" "),n("ProjectCard",{attrs:{image:"/projects/tmech.png",hideBorder:"true"}},[n("p",[n("strong",[e._v("Accurate and Real-time 3D Tracking for the Following Robots by Fusing Vision and Ultra-sonar Information")])]),e._v(" "),n("p",[n("strong",[e._v("Mengmeng Wang")]),e._v(", Yong Liu*, Daobilige Su, Yufan Liao, Lei Shi and Jinhong Xu.")]),e._v(" "),n("p",[e._v("IEEE/ASME Transactions on Mechatronics, 2018")]),e._v(" "),n("p",[e._v("["),n("a",{attrs:{href:"https://ieeexplore.ieee.org/document/8327519",target:"_blank",rel:"noopener noreferrer"}},[e._v("PDF"),n("OutboundLink")],1),e._v("] ["),n("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/34920240",target:"_blank",rel:"noopener noreferrer"}},[e._v("BLOG"),n("OutboundLink")],1),e._v("]")])]),e._v(" "),n("ProjectCard",{attrs:{image:"/projects/LMCF.png",hideBorder:"true"}},[n("p",[n("strong",[e._v("Large Margin Object Tracking with Circulant Feature Map")])]),e._v(" "),n("p",[n("strong",[e._v("Mengmeng Wang")]),e._v(", Yong Liu‚àó, Zeyi Huang")]),e._v(" "),n("p",[e._v("IEEE Conference on Computer Vision and Pattern Recognition ("),n("strong",[e._v("CVPR")]),e._v("), 2017")]),e._v(" "),n("p",[e._v("["),n("a",{attrs:{href:"https://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_Large_Margin_Object_CVPR_2017_paper.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("PDF"),n("OutboundLink")],1),e._v("] ["),n("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/25761718",target:"_blank",rel:"noopener noreferrer"}},[e._v("BLOG"),n("OutboundLink")],1),e._v("] ["),n("a",{attrs:{href:"https://github.com/sallymmx/LMCF",target:"_blank",rel:"noopener noreferrer"}},[e._v("Results"),n("OutboundLink")],1),e._v("]")])]),e._v(" "),n("h2",{attrs:{id:"awards-honors"}},[e._v("Awards & Honors")]),e._v(" "),n("ul",[n("li",[n("p",[n("a",{attrs:{href:"https://www.cie-info.org.cn/site/content/4047.html",target:"_blank",rel:"noopener noreferrer"}},[n("strong",[e._v("Excellent master dissertation")]),n("OutboundLink")],1),e._v(" "),n("strong",[e._v("of "),n("em",[e._v("Chinese Institute of Electronics (‰∏≠ÂõΩÁîµÂ≠êÂ≠¶‰ºö)")]),e._v(", 2020")]),e._v(" üéâ")])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Freshmen Scholarship, Zhejiang University, 2020")])])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Excellent Master Thesis, Zhejiang Province, 2020")])])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Outstanding Graduate, Zhejiang Province & Zhejiang University, 2018")])])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Google Women Techmaker, Global,  2017")]),e._v(" üéâ")])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("National Scholarship, 2017")])])])])],1)}),[],!1,null,null,null);n.default=o.exports}}]);