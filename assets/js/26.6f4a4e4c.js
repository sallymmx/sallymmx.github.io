(window.webpackJsonp=window.webpackJsonp||[]).push([[26],{282:function(n,e,i){},302:function(n,e,i){"use strict";i(282)},325:function(n,e,i){"use strict";i.r(e);i(302);var o=i(14),a=Object(o.a)({},(function(){var n=this,e=n._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":n.$parent.slotKey}},[e("p",[e("em",[n._v("Here are details of some works ðŸ“š Thanks to all the co-authors for our works.")])]),n._v(" "),e("h2",{attrs:{id:"publications"}},[n._v("Publications")]),n._v(" "),e("h3",{attrs:{id:"_2024"}},[n._v("2024")]),n._v(" "),e("ol",[e("li",[e("strong",[n._v("Wang M")]),n._v(", Xing J, Jiang B, et al. A Multimodal, Multi-Task Adapting Framework for Video Action Recognition[C]//Proceedings of the "),e("strong",[n._v("AAAI")]),n._v(" Conference on Artificial Intelligence. 2024, 38(6): 5517-5525.  "),e("strong",[n._v("("),e("font",{attrs:{color:"red"}},[n._v("Oral")]),n._v(")")],1)]),n._v(" "),e("li",[n._v("Lin H, "),e("strong",[n._v("Wang M")]),n._v(", Chen Y, et al. DreamSalon: A Staged Diffusion Framework for Preserving Identity-Context in Editable Face Generation[J]. arXiv preprint arXiv:2403.19235, 2024. "),e("strong",[n._v("Corresponding Author")])]),n._v(" "),e("li",[n._v("Jia, C., Luo, M., Dang, Z., Dai, G., Chang, X., "),e("strong",[n._v("Wang, M.")]),n._v(", & Wang, J. (2024, March). Ssmg: Spatial-semantic map guided diffusion model for free-form layout-to-image generation. In Proceedings of the "),e("strong",[n._v("AAAI")]),n._v(" Conference on Artificial Intelligence (Vol. 38, No. 3, pp. 2480-2488).")])]),n._v(" "),e("hr"),n._v(" "),e("h3",{attrs:{id:"_2023"}},[n._v("2023")]),n._v(" "),e("ol",[e("li",[e("strong",[n._v("Wang M")]),n._v(", Xing J, Mei J, et al. ActionCLIP: Adapting Language-Image Pretrained Models for Video Action Recognition[J]. IEEE Transactions on Neural Networks and Learning Systems ("),e("strong",[n._v("TNNLS")]),n._v("), 2023.")]),n._v(" "),e("li",[e("strong",[n._v("Wang M")]),n._v(", Ma T, Zuo X, et al. Correlation pyramid network for 3d single object tracking[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition  ("),e("strong",[n._v("CVPR")]),n._v("). 2023: 3215-3224.")]),n._v(" "),e("li",[n._v("Xing J, "),e("strong",[n._v("Wang M")]),n._v(", Ruan Y, et al. Boosting Few-shot Action Recognition with Graph-guided Hybrid Matching[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023: 1740-1750.")]),n._v(" "),e("li",[n._v("Liu L, Song X, "),e("strong",[n._v("Wang M")]),n._v(", et al. AGDF-Net: Learning Domain Generalizable Depth Features with Adaptive Guidance Fusion[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence ("),e("strong",[n._v("TPAMI")]),n._v("), 2023.ðŸŽ‰ðŸŽ‰ðŸŽ‰")]),n._v(" "),e("li",[n._v("Ma T, "),e("strong",[n._v("Wang M")]),n._v(", Xiao J, et al. Synchronize Feature Extracting and Matching: A Single Branch Framework for 3D Object Tracking[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision ("),e("strong",[n._v("ICCV")]),n._v("). 2023: 9953-9963.")]),n._v(" "),e("li",[n._v("Chen, J., Bai, S., Huang, T., "),e("strong",[n._v("Wang, M")]),n._v("., Tian, G., & Liu, Y. (2023). Data-free quantization via mixed-precision compensation without fine-tuning. Pattern Recognition ("),e("strong",[n._v("PR")]),n._v("), "),e("em",[n._v("143")]),n._v(", 109780.")]),n._v(" "),e("li",[n._v("Xing J, "),e("strong",[n._v("Wang M")]),n._v(", Mu B, et al. Revisiting the Spatial and Temporal Modeling for Few-shot Action Recognition[J]. "),e("strong",[n._v("AAAI")]),n._v(" 2023. "),e("strong",[n._v("Corresponding Author")])]),n._v(" "),e("li",[n._v("Lv, J., Lang, X., Xu, J., "),e("strong",[n._v("Wang, M.")]),n._v(", Liu, Y., & Zuo, X. (2023). Continuous-time fixed-lag smoothing for lidar-inertial-camera slam. IEEE/ASME Transactions on Mechatronics ("),e("strong",[n._v("TMech")]),n._v(").")])]),n._v(" "),e("hr"),n._v(" "),e("h3",{attrs:{id:"_2022"}},[n._v("2022")]),n._v(" "),e("ol",[e("li",[e("p",[e("strong",[n._v("Mengmeng Wang")]),n._v(", Jiazheng Xing, Jing Su,  Jun Chen, Yong Liu*. Learning SpatioTemporal and Motion Features in a Unified 2D Network for Action Recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence ("),e("strong",[n._v("TPAMI")]),n._v("), 2022.ðŸŽ‰ðŸŽ‰ðŸŽ‰")])]),n._v(" "),e("li",[e("p",[e("strong",[n._v("Wang, M")]),n._v("., Mei, J., Liu, L., Tian, G., Liu, Y., & Pan, Z. (2022). Delving Deeper Into Mask Utilization in Video Object Segmentation. "),e("em",[n._v("IEEE Transactions on Image Processing")]),n._v(" ("),e("strong",[n._v("TIP")]),n._v("), "),e("em",[n._v("31")]),n._v(", 6255-6266.")])]),n._v(" "),e("li",[e("p",[n._v("Xu, C., Zhang, J., "),e("strong",[n._v("Wang, M")]),n._v("., Tian, G., & Liu, Y. (2022). Multilevel Spatial-Temporal Feature Aggregation for Video Object Detection. "),e("em",[n._v("IEEE Transactions on Circuits and Systems for Video Technology")]),n._v(" ("),e("strong",[n._v("TCSVT")]),n._v("), "),e("em",[n._v("32")]),n._v("(11), 7809-7820.")])]),n._v(" "),e("li",[e("p",[n._v("Ma, T., Geng, S., "),e("strong",[n._v("Wang, M")]),n._v("., Xu, S., Li, H., Zhang, B., ... & Qiao, Y. (2022). Unleashing the Potential of Vision-Language Models for Long-Tailed Visual Recognition. "),e("strong",[n._v("BMVC")]),n._v(" 2022.")])]),n._v(" "),e("li",[e("p",[n._v("Yang Y, "),e("strong",[n._v("Wang M")]),n._v(", Mei J, et al. Exploiting semantic-level affinities with a mask-guided network for temporal action proposal in videos[J]. Applied Intelligence, 2022: 1-21.")])]),n._v(" "),e("li",[e("p",[n._v("Lin H, "),e("strong",[n._v("Wang M")]),n._v(", Liu Y, et al. Correlation-based and content-enhanced network for video style transfer[J]. Pattern Analysis and Applications, 2022: 1-13.")]),n._v(" "),e("hr")])]),n._v(" "),e("h3",{attrs:{id:"_2021"}},[n._v("2021")]),n._v(" "),e("ol",[e("li",[e("strong",[n._v("Wang, Mengmeng")]),n._v(', Jiazheng Xing, and Yong Liu. "Actionclip: A new paradigm for video action recognition." '),e("em",[n._v("arXiv preprint arXiv:2109.08472")]),n._v(" (2021).")]),n._v(" "),e("li",[n._v("Deng C, "),e("strong",[n._v("Wang M")]),n._v("*, Liu L, et al. Extended feature pyramid network for small object detection[J]. IEEE Transactions on Multimedia ("),e("strong",[n._v("TMM")]),n._v("), 2021.  "),e("strong",[n._v("corresponding author")])]),n._v(" "),e("li",[n._v("Li Z, "),e("strong",[n._v("Wang M,")]),n._v(" Mei J, et al. Mail: A unified mask-image-language trimodal network for referring image segmentation[J]. arXiv preprint arXiv:2111.10747, 2021. "),e("strong",[n._v("Equal first contributor")]),n._v(".")]),n._v(" "),e("li",[n._v("Tian, G., Sun, Y., Liu, Y., Zeng, X., "),e("strong",[n._v("Wang, M")]),n._v("., Liu, Y., ... & Chen, J. (2021). Adding before pruning: Sparse filter fusion for deep convolutional neural networks via auxiliary attention. "),e("em",[n._v("IEEE Transactions on Neural Networks and Learning Systems")]),n._v(" ("),e("strong",[n._v("TNNLS")]),n._v(").")]),n._v(" "),e("li",[n._v("Mei J, "),e("strong",[n._v("Wang M")]),n._v(", Lin Y, et al. Transvos: Video object segmentation with transformers[J]. arXiv preprint arXiv:2106.00588, 2021.")]),n._v(" "),e("li",[n._v("Huang, T., Zou, H., Cui, J., Yang, X., "),e("strong",[n._v("Wang, M")]),n._v("., Zhao, X., ... & Liu, Y. (2021). RFNet: recurrent forward network for dense point cloud completion. In "),e("em",[n._v("Proceedings of the IEEE/CVF international conference on computer vision")]),n._v(" ("),e("strong",[n._v("ICCV")]),n._v(") (pp. 12508-12517).")]),n._v(" "),e("li",[n._v("Liu L, Song X, "),e("strong",[n._v("Wang M")]),n._v(", et al. Self-supervised monocular depth estimation for all day images using domain separation[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision ("),e("strong",[n._v("ICCV")]),n._v("). 2021: 12737-12746.")]),n._v(" "),e("li",[n._v("Xiaoyang Lyu, Liang Liu, "),e("strong",[n._v("Mengmeng Wang")]),n._v(", Xin Kong, Lina Liu, Yong Liu*, Xinxin Chen, Yi Yuan, HR-Depth : High Resolution Self-Supervised Monocular Depth Estimation,The Association for the Advance of Artificial Intelligence ("),e("strong",[n._v("AAAI")]),n._v("), 2021")]),n._v(" "),e("li",[n._v("Lina Liu, Xibin Song, Xiaoyang Lyu, Junwei Diao, "),e("strong",[n._v("Mengmeng Wang")]),n._v(", Yong Liu*, Liangjun Zhang, FCFR-Net: Feature Fusion based Coarse-to-Fine Residual Learning for Depth Completion, The Association for the Advance of Artificial Intelligence ("),e("strong",[n._v("AAAI")]),n._v("), 2021")]),n._v(" "),e("li",[n._v("Jilin Tang, Yi Yuan*, Tianjia Shao, Yong Liu, "),e("strong",[n._v("Mengmeng Wang")]),n._v(", Kun Zhou, Structure-aware Person Image Generation with Pose Decomposition and Semantic Correlation, the Association for the Advance of Artificial Intelligence ("),e("strong",[n._v("AAAI")]),n._v("), 2021")]),n._v(" "),e("li",[n._v("Guangming Yaoâ€ , Tianjia Shaoâ€ , Yi Yuan*, Shuang Li, Shanqi Liu, Yong Liu, "),e("strong",[n._v("Mengmeng Wang")]),n._v(", Kun Zhou, One-shot Face Reenactment Using Appearance Adaptive Normalizationï¼Œthe Association for the Advance of Artificial Intelligence ("),e("strong",[n._v("AAAI")]),n._v("), 2021")]),n._v(" "),e("li",[n._v("Xu, C., Wu, X., Li, Y., Jin, Y., "),e("strong",[n._v("Wang, M")]),n._v("*, & Liu, Y. (2021). Cross-modality online distillation for multi-view action recognition. "),e("em",[n._v("Neurocomputing")]),n._v(", "),e("em",[n._v("456")]),n._v(", 384-393. "),e("strong",[n._v("corresponding author")])])]),n._v(" "),e("hr"),n._v(" "),e("h3",{attrs:{id:"before-2021"}},[n._v("Before 2021")]),n._v(" "),e("ol",[e("li",[n._v("Hao Zhang, "),e("strong",[n._v("Mengmeng Wang")]),n._v(", Yong Liu*, Yi Yuan. FDN: Feature Decoupling Network for Head Pose Estimation, Proceedings of the 34th AAAI Conference on Artificial Intelligence ("),e("strong",[n._v("AAAI")]),n._v("), New York, USA, 7-12 Feb. 2020.")]),n._v(" "),e("li",[n._v("Zhang, J., Xu, C., Liu, L., "),e("strong",[n._v("Wang, M.")]),n._v(", Wu, X., Liu, Y., & Jiang, Y. (2020). Dtvnet: Dynamic time-lapse video generation via single still image. In "),e("em",[n._v("Computer Visionâ€“ECCV 2020: 16th European Conference, Glasgow, UK, August 23â€“28, 2020, Proceedings, Part V 16")]),n._v(" (pp. 300-315). Springer International Publishing.")]),n._v(" "),e("li",[n._v("Xianfang Zeng, Yusu Pan, "),e("strong",[n._v("Mengmeng Wang")]),n._v(", Jiangning Zhang, Yong Liu*. Realistic Face Reenactment via Self-Supervised Disentangling of Identity and Pose, Proceedings of the 34th AAAI Conference on Artificial Intelligence ("),e("strong",[n._v("AAAI")]),n._v("), New York, USA, 7-12 Feb. 2020")]),n._v(" "),e("li",[n._v("Jiangning Zhang, Xianfang Zeng, "),e("strong",[n._v("Mengmeng Wang")]),n._v(", Yusu Pan, Liang Liu,Yong Liu*, Yu Ding, Changjie Fan. FReeNet: Multi-Identity Face Reenactment, 2019 IEEE Conference on Computer Vision and Pattern Recognition ("),e("strong",[n._v("CVPR")]),n._v("), Seattle, USA, 16 - 18 June, 2020ï¼Œ "),e("strong",[n._v("Equal First Author")])]),n._v(" "),e("li",[n._v("Jiangning Zhang, Chao Xu, Lina Liu, "),e("strong",[n._v("Mengmeng Wang")]),n._v(", Xia Wu, Yong Liu*, DTVNet: Dynamic Time-lapse Video Generation via Single Still Image, European Conference on Computer Vision ("),e("strong",[n._v("ECCV")]),n._v("), 2020,")]),n._v(" "),e("li",[n._v("Xianfang Zeng, Yusu Pan, Hao Zhang, "),e("strong",[n._v("Mengmeng Wang")]),n._v(", Guanzhong Tian, Yong Liu*,  Unpaired Salient Object Translation via Spatial Attention Prior, Neurocomputing")]),n._v(" "),e("li",[n._v("Kong, X., Yang, X., Zhai, G., Zhao, X., Zeng, X., "),e("strong",[n._v("Wang, M")]),n._v("., ... & Wen, F. (2020). Semantic graph based place recognition for 3d point clouds. In "),e("em",[n._v("2020 IEEE/RSJ International Conference on Intelligent Robots and Systems ("),e("strong",[n._v("IROS")]),n._v(")")]),n._v(" (pp. 8216-8223).")]),n._v(" "),e("li",[n._v("Boyuan Jiang, "),e("strong",[n._v("Mengmeng Wang")]),n._v(" *, Weihao Gan, Wei Wu, Junjie Yan. STM: SpatioTemporal and motion encoding for action recognition, Proceedings of the IEEE International Conference on Computer Vision ("),e("strong",[n._v("ICCV")]),n._v("). 2019: 2000-2009. "),e("strong",[n._v("Corresponding Author")])]),n._v(" "),e("li",[e("strong",[n._v("Mengmeng Wang")]),n._v(", Yong Liu*, Daobilige Su, Yufan Liao, Lei Shi and Jinhong Xu. Accurate and Real-time 3D Tracking for the Following Robots by Fusing Vision and Ultra-sonar Information. IEEE/ASME Transactions on Mechatronics, 2018, 23(3): 997 - 1006.ï¼ˆIF=4.943ï¼ŒSCIï¼‰")]),n._v(" "),e("li",[e("strong",[n._v("Mengmeng Wang")]),n._v(", Yong Liu*, Zeyi Huang. Large Margin Object Tracking with Circulant Feature Maps, 2017 IEEE Conference on Computer Vision and Pattern Recognition ("),e("strong",[n._v("CVPR")]),n._v("), Honolulu, Hawaii, 22-25 July, 2017.")]),n._v(" "),e("li",[e("strong",[n._v("Mengmeng Wang")]),n._v(", Daobilige Su, Lei Shi, Yong Liu*, Jaime Valls Miro.\tReal-Time 3D Human Tracking for Mobile Robots with Multisensors, 2017 IEEE International Conference on Robotics & Automation ("),e("strong",[n._v("ICRA")]),n._v("), Singapore, May 29-June 3, 2017.")]),n._v(" "),e("li",[e("strong",[n._v("Mengmeng Wang")]),n._v(", Yong Liu, Rong Xiong. Robust object tracking with a hierarchical ensemble framework, 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems ("),e("strong",[n._v("IROS")]),n._v("), Korean, Oct.9 - Oct. 14, 2016, 2016: 438-445.")])])])}),[],!1,null,null,null);e.default=a.exports}}]);